# AI Voice Detection API - Development Guide

## ğŸ“‹ Project Overview

Multi-language AI voice detection system that identifies whether audio is AI-generated or human-spoken across 5 languages: Tamil, English, Hindi, Malayalam, and Telugu.

**Hackathon:** GUVI AI Hackathon  
**Problem Statement:** AI-Generated Voice Detection (Multi-Language)  
**Timeline:** 7 days  
**Current Status:** Feature 2 Complete âœ“

---

## ğŸ¯ Project Goals

- âœ… Build REST API for voice authentication detection
- âœ… Support 5 languages (Tamil, English, Hindi, Malayalam, Telugu)
- âœ… Accept Base64-encoded MP3 audio
- âœ… Return classification (AI_GENERATED or HUMAN) with confidence score
- âœ… Achieve 75-80% accuracy without training data
- âœ… Deploy production-ready API

---

## ğŸ—ï¸ Architecture & Strategy

### **Chosen Approach:** Hybrid Detection System

**Why this approach:**

- â±ï¸ **Time constraint:** 2-3 hours/day for 7 days
- ğŸ“Š **No training data** available initially
- ğŸ¯ **Goal:** Balance between accuracy and speed
- âœ… **Feasible:** Uses pre-trained models + analytical features

### **Technology Stack**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FastAPI REST API                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Wav2Vec2     â”‚  +   â”‚  Acoustic    â”‚   â”‚
â”‚  â”‚ Embeddings   â”‚      â”‚  Features    â”‚   â”‚
â”‚  â”‚ (HuggingFace)â”‚      â”‚  (Librosa)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â†“                      â†“           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚      Hybrid Detection Logic          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                    â†“                       â”‚
â”‚         AI_GENERATED or HUMAN              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Core Components**

1. **Audio Processor** - Handles Base64 decoding, validation, preprocessing
2. **Model Detector** - Wav2Vec2 embeddings + heuristic analysis
3. **FastAPI Server** - REST API with authentication
4. **Deployment** - Railway/Render cloud deployment

---

## ğŸ“… Development Roadmap (7 Days)

### âœ… **Day 1-2: Foundation (COMPLETED)**

#### **Feature 1: Project Setup & Environment** âœ“

**Status:** Complete  
**Time Spent:** 1.5 hours

**What was built:**

- âœ… Virtual environment setup
- âœ… Dependency installation (FastAPI, PyTorch, Librosa)
- âœ… Configuration management (`config.py`)
- âœ… Basic FastAPI application
- âœ… Health check endpoints
- âœ… Environment variables setup
- âœ… Verification scripts

**Files Created:**

```
â”œâ”€â”€ .env                    # Environment configuration
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ config.py              # Application config
â”œâ”€â”€ main.py                # FastAPI app
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ verify_setup.py        # Setup verification
```

**Verification:**

```bash
python verify_setup.py
python main.py
# Visit: http://localhost:8000/docs
```

---

#### **Feature 2: Audio Processing Pipeline** âœ“

**Status:** Complete  
**Time Spent:** 2.5 hours

**What was built:**

- âœ… Base64 audio decoding
- âœ… Audio loading and validation
- âœ… Preprocessing (normalization, trimming, padding)
- âœ… Feature extraction (40+ acoustic features)
- âœ… Error handling for invalid audio
- âœ… Audio information extraction
- âœ… Comprehensive testing suite

**Files Created:**

```
â”œâ”€â”€ audio_processor.py           # Main audio processor
â”œâ”€â”€ download_sample.py           # Sample audio downloader
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ audio_helpers.py         # Utility functions
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_audio_processor.py      # Unit tests
    â””â”€â”€ test_with_real_audio.py      # Integration tests
```

**Features Extracted:**

- Spectral features (centroid, rolloff, bandwidth)
- Zero crossing rate
- MFCC (13 coefficients)
- RMS energy
- Spectral contrast

**Verification:**

```bash
python tests/test_audio_processor.py
python download_sample.py
python tests/test_with_real_audio.py
```

---

### ğŸ”„ **Day 3: Model Integration (IN PROGRESS)**

#### **Feature 3: Pre-trained Model Integration**

**Status:** Ready to implement  
**Estimated Time:** 2.5 hours

**What will be built:**

- â³ Wav2Vec2 model integration (HuggingFace)
- â³ Embedding extraction pipeline
- â³ Heuristic-based AI detection (no training needed)
- â³ Hybrid detector (embeddings + acoustic features)
- â³ Model testing and validation

**Files to Create:**

```
â”œâ”€â”€ model_detector.py                  # Wav2Vec2 detector
â”œâ”€â”€ compare_detectors.py               # Comparison tool
â”œâ”€â”€ optimize_model.py                  # Optimization guide
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_model_detector.py         # Model unit tests
    â””â”€â”€ test_model_with_real_audio.py  # Model integration tests
```

**Key Components:**

1. **Wav2Vec2Detector** - Pre-trained model wrapper
2. **Embedding Analysis** - Detect AI patterns in embeddings
3. **HybridDetector** - Combine multiple signals

**Next Steps:**

```bash
# Update requirements
pip install transformers datasets accelerate

# Implement model_detector.py
# Run tests
python tests/test_model_detector.py
```

---

### ğŸ“‹ **Day 4: API Integration (PLANNED)**

#### **Feature 4: Complete API Implementation**

**Status:** Planned  
**Estimated Time:** 2 hours

**What will be built:**

- â³ POST endpoint for voice detection
- â³ Request validation (language, format, Base64)
- â³ API key authentication
- â³ Response formatting (JSON structure)
- â³ Error handling and status codes
- â³ Rate limiting (optional)

**Files to Create/Update:**

```
â”œâ”€â”€ main.py                  # Update with detection endpoint
â”œâ”€â”€ schemas.py               # Pydantic models
â”œâ”€â”€ middleware.py            # Authentication, logging
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_api_endpoints.py  # API tests
```

**Endpoint Specification:**

```
POST /api/voice-detection
Headers:
  - x-api-key: YOUR_API_KEY
  - Content-Type: application/json

Body:
{
  "language": "Tamil",
  "audioFormat": "mp3",
  "audioBase64": "..."
}

Response:
{
  "status": "success",
  "language": "Tamil",
  "classification": "AI_GENERATED",
  "confidenceScore": 0.87,
  "explanation": "..."
}
```

---

### ğŸ§ª **Day 5: Testing & Validation (PLANNED)**

#### **Feature 5: Comprehensive Testing**

**Status:** Planned  
**Estimated Time:** 3 hours

**What will be built:**

- â³ Test with all 5 languages
- â³ Collect diverse audio samples
- â³ Accuracy measurement
- â³ Edge case testing
- â³ Performance benchmarking
- â³ Fine-tune detection thresholds

**Test Categories:**

1. **Language Coverage** - Test Tamil, English, Hindi, Malayalam, Telugu
2. **Audio Quality** - Test with different bitrates, noise levels
3. **AI Voices** - ElevenLabs, Google TTS, Azure TTS samples
4. **Human Voices** - Record own voice, use public datasets
5. **Edge Cases** - Very short audio, silence, music

**Files to Create:**

```
â””â”€â”€ tests/
    â”œâ”€â”€ test_all_languages.py
    â”œâ”€â”€ test_edge_cases.py
    â”œâ”€â”€ test_performance.py
    â””â”€â”€ accuracy_report.py
```

---

### ğŸš€ **Day 6: Deployment Preparation (PLANNED)**

#### **Feature 6: Production Deployment**

**Status:** Planned  
**Estimated Time:** 2.5 hours

**What will be built:**

- â³ Docker containerization
- â³ Environment configuration for production
- â³ Railway/Render deployment setup
- â³ Monitoring and logging
- â³ API documentation (Swagger)

**Files to Create:**

```
â”œâ”€â”€ Dockerfile              # Container configuration
â”œâ”€â”€ docker-compose.yml      # Local testing
â”œâ”€â”€ railway.json            # Railway config
â”œâ”€â”€ render.yaml             # Render config
â””â”€â”€ .dockerignore          # Docker ignore
```

**Deployment Platforms:**

- **Primary:** Railway (recommended)
- **Backup:** Render
- **Alternative:** Docker on any cloud

---

### ğŸ¨ **Day 7: Polish & Documentation (PLANNED)**

#### **Feature 7: Final Polish**

**Status:** Planned  
**Estimated Time:** 2.5 hours

**What will be done:**

- â³ API documentation refinement
- â³ README completion
- â³ Demo video/screenshots
- â³ Performance optimization
- â³ Final testing in production
- â³ Presentation preparation

**Deliverables:**

- âœ… Deployed API URL
- âœ… API documentation
- âœ… GitHub repository
- âœ… Demo samples
- âœ… Performance metrics

---

## ğŸ“Š Current Project Structure

```
ai-voice-detection/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # This file
â”œâ”€â”€ ğŸ“„ .env                         # Environment variables
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git ignore
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“„ config.py                    # Configuration âœ“
â”œâ”€â”€ ğŸ“„ main.py                      # FastAPI app âœ“
â”œâ”€â”€ ğŸ“„ audio_processor.py           # Audio processing âœ“
â”œâ”€â”€ ğŸ“„ verify_setup.py              # Setup verification âœ“
â”œâ”€â”€ ğŸ“„ download_sample.py           # Sample downloader âœ“
â”‚
â”œâ”€â”€ ğŸ“ models/
â”‚   â””â”€â”€ (Wav2Vec2 cache will be here)
â”‚
â”œâ”€â”€ ğŸ“ utils/
â”‚   â””â”€â”€ ğŸ“„ audio_helpers.py         # Helper functions âœ“
â”‚
â”œâ”€â”€ ğŸ“ tests/
â”‚   â”œâ”€â”€ ğŸ“„ test_audio_processor.py      âœ“
â”‚   â””â”€â”€ ğŸ“„ test_with_real_audio.py      âœ“
â”‚
â””â”€â”€ ğŸ“ test_samples/
    â”œâ”€â”€ sample_voice.mp3            # Downloaded sample
    â””â”€â”€ feature_summary.json        # Generated features
```

---

## ğŸ”§ Setup Instructions

### Prerequisites

- Python 3.8 or higher
- 2GB free disk space (for models)
- Stable internet connection (for model download)

### Installation

```bash
# 1. Clone repository
git clone <your-repo-url>
cd ai-voice-detection

# 2. Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Mac/Linux)
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Verify setup
python verify_setup.py

# 5. Download sample audio
python download_sample.py

# 6. Run tests
python tests/test_audio_processor.py

# 7. Start server
python main.py
```

---

## ğŸ§ª Testing Guide

### Current Tests Available

```bash
# Test 1: Setup verification
python verify_setup.py

# Test 2: Audio processor with synthetic audio
python tests/test_audio_processor.py

# Test 3: Audio processor with real MP3
python tests/test_with_real_audio.py

# Test 4: Run API server
python main.py
# Visit: http://localhost:8000/docs
```

---

## ğŸ“ Dependencies

### Core Dependencies

```
fastapi==0.104.1          # Web framework
uvicorn==0.24.0           # ASGI server
librosa==0.10.1           # Audio processing
torch==2.1.0              # Deep learning
transformers==4.35.0      # HuggingFace models
```

### Full List

See `requirements.txt` for complete dependency list.

---

## ğŸ¯ Performance Targets

| Metric           | Target        | Current Status         |
| ---------------- | ------------- | ---------------------- |
| Accuracy         | 75-80%        | TBD (after Feature 3)  |
| Response Time    | < 3 seconds   | TBD (after Feature 4)  |
| Languages        | 5/5 supported | 5/5 âœ“                  |
| Audio Format     | MP3           | Supported âœ“            |
| Max Audio Length | 30 seconds    | Supported âœ“            |
| API Uptime       | 99%+          | TBD (after deployment) |

---

## ğŸš€ Quick Start (For New Developers)

```bash
# Complete setup in 5 steps:

# Step 1: Setup environment
python -m venv venv && source venv/bin/activate  # or venv\Scripts\activate on Windows

# Step 2: Install everything
pip install -r requirements.txt

# Step 3: Verify it works
python verify_setup.py

# Step 4: Test with sample
python download_sample.py && python tests/test_with_real_audio.py

# Step 5: Start developing
python main.py
```

---

## ğŸ“– API Documentation (Planned)

### Endpoint

```
POST /api/voice-detection
```

### Request Format

```json
{
  "language": "Tamil",
  "audioFormat": "mp3",
  "audioBase64": "SUQzBAAAAAAAI1RTU0UAAAAPAAADTGF2ZjU2LjM2LjEwMAAAAAAA..."
}
```

### Response Format

```json
{
  "status": "success",
  "language": "Tamil",
  "classification": "AI_GENERATED",
  "confidenceScore": 0.87,
  "explanation": "Detected consistent embedding patterns, sparse spectral features"
}
```

### Error Response

```json
{
  "status": "error",
  "message": "Invalid API key or malformed request"
}
```

---

## ğŸ” Security

- âœ… API key authentication required
- âœ… Input validation for all requests
- âœ… Audio size limits (10MB max)
- âœ… Rate limiting (planned)
- âœ… HTTPS in production (deployment)

---

## ğŸ› Known Issues & Limitations

### Current Limitations

1. **No training data** - Using heuristic detection (75-80% accuracy expected)
2. **Model size** - Wav2Vec2 is ~360MB (cached after first download)
3. **Processing time** - 1-3 seconds per audio (can be optimized)

### Planned Improvements

1. Fine-tune thresholds with real test data
2. Add model quantization for smaller size
3. Implement caching for faster repeated requests
4. Add batch processing support

---

## ğŸ“š Resources & References

### Documentation

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Librosa Documentation](https://librosa.org/)
- [HuggingFace Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base)
- [Problem Statement](./problem_statement.md)

### Datasets (for testing)

- [Common Voice by Mozilla](https://commonvoice.mozilla.org/)
- [ElevenLabs](https://elevenlabs.io/) - AI voice generation
- [Google Cloud TTS](https://cloud.google.com/text-to-speech)

---

## ğŸ‘¥ Team & Contact

**Developer:** [Your Name]  
**Hackathon:** GUVI AI Hackathon 2025  
**Timeline:** January 21-28, 2025  
**Repository:** [GitHub URL]

---

## ğŸ“ˆ Progress Tracking

### Completion Status

```
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60% Complete

âœ“ Feature 1: Project Setup (100%)
âœ“ Feature 2: Audio Processing (100%)
â³ Feature 3: Model Integration (0%)
â³ Feature 4: API Implementation (0%)
â³ Feature 5: Testing (0%)
â³ Feature 6: Deployment (0%)
â³ Feature 7: Documentation (0%)
```

### Daily Log

**Day 1 (Jan 21):**

- âœ… Project structure created
- âœ… Environment setup complete
- âœ… Basic FastAPI running

**Day 2 (Jan 22):**

- âœ… Audio processor implemented
- âœ… Feature extraction working
- âœ… All tests passing

**Day 3 (Jan 23):**

- â³ Model integration in progress

---

## ğŸ“ Learning Outcomes

### Technical Skills Gained

- âœ… Audio processing with Librosa
- âœ… FastAPI development
- â³ HuggingFace Transformers
- â³ Model deployment
- â³ REST API design

### Best Practices

- âœ… Modular code structure
- âœ… Comprehensive testing
- âœ… Configuration management
- âœ… Error handling
- âœ… Documentation

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ™ Acknowledgments

- HuggingFace for pre-trained models
- FastAPI community
- Librosa developers
- GUVI for organizing the hackathon

---

**Last Updated:** January 23, 2025  
**Status:** Feature 2 Complete âœ“  
**Next:** Feature 3 - Model Integration

---

## ğŸš¦ Quick Commands Reference

```bash
# Setup
python verify_setup.py

# Testing
python tests/test_audio_processor.py
python tests/test_with_real_audio.py

# Development
python main.py

# Download sample
python download_sample.py

# Future commands (after Feature 3)
python tests/test_model_detector.py
python compare_detectors.py
```

---

_This README will be updated as features are completed._
